# Copyright 2017, 2020, 2023, 2024 IBM Corporation
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.

name=mq-source
connector.class=com.ibm.eventstreams.connect.mqsource.MQSourceConnector

# You can increase this for higher throughput, but message ordering will be lost
# Exactly-once message delivery requires tasks.max to be 1
# (see README.md for more details).
tasks.max=1

# The name of the target Kafka topic - required
topic=

# The name of the MQ queue manager - required
mq.queue.manager=

# The connection mode to connect to MQ - client (default) or bindings - optional
# mq.connection.mode=client
# mq.connection.mode=bindings

# A list of one or more host(port) entries for connecting to the queue manager. Entries are separated with a comma - required (unless using bindings or CCDT)
mq.connection.name.list=

# The name of the server-connection channel - required (unless using bindings or CCDT)
mq.channel.name=

# The name of the source MQ queue - required
mq.queue=

# This is required for exactly-once delivery. If not supplied, message delivery will be at-least-once.
# (see README.md for more details).
# mq.exactly.once.state.queue=

# The user name for authenticating with the queue manager - optional
# mq.user.name=

# The password for authenticating with the queue manager - optional
# mq.password=

# Alternatively can use a ConfigProvider for externalising secrets (see README.md for more details)
# Variable references are of the form ${provider:[path:]key} where the path is optional,
# depending on the ConfigProvider implementation.
# mq.password=${file:/var/run/secret.properties:secret-key}

# Whether to use MQ connection security parameters (MQCSP) to provide credentials - optional
# mq.user.authentication.mqcsp=

# The CCDT URL to use to establish a client connection to the queue manager - optional
# mq.ccdt.url=

# The record builders control conversion of data between the messages in MQ and the internal Kafka Connect representation - required
mq.record.builder=com.ibm.eventstreams.connect.mqsource.builders.DefaultRecordBuilder
# mq.record.builder=com.ibm.eventstreams.connect.mqsource.builders.JsonRecordBuilder

# Whether to interpret the message body as a JMS message type (default false) - optional
# mq.message.body.jms=

# The JMS message header to use as the Kafka record key - optional
# Valid values are JMSMessageID, JMSCorrelationID, JMSCorrelationIDAsBytes and JMSDestination
# Don't forget to set key.converter to a compatible converter as described in README.md
# mq.record.builder.key.header=

# Whether to copy JMS message properties to Kafka headers
# mq.jms.properties.copy.to.kafka.headers=

# The name of the cipher suite for TLS (SSL) connection (default blank, meaning do not use TLS) - optional
# See https://www.ibm.com/support/knowledgecenter/en/SSFKSJ_9.1.0/com.ibm.mq.dev.doc/q113220_.htm for valid values
# mq.ssl.cipher.suite=

# The distinguished name pattern of the TLS (SSL) peer - optional
# mq.ssl.peer.name=

# Location and password for the keystore and truststore for SSL (TLS) connections
# mq.ssl.keystore.location=
# mq.ssl.keystore.password=
# mq.ssl.truststore.location=
# mq.ssl.truststore.password=

# Whether to set system property to control use of IBM cipher mappings - optional
# mq.ssl.use.ibm.cipher.mappings=false

# Whether to enable reading of all MQMD fields (default false) - optional
# mq.message.mqmd.read=

# The maximum number of messages in a batch (unit of work) - optional
# mq.batch.size=250

# The converters control conversion of data between the internal Kafka Connect representation and the messages in Kafka.
# key.converter=org.apache.kafka.connect.converters.ByteArrayConverter
key.converter=org.apache.kafka.connect.storage.StringConverter
# key.converter=org.apache.kafka.connect.json.JsonConverter

# value.converter=org.apache.kafka.connect.converters.ByteArrayConverter
value.converter=org.apache.kafka.connect.storage.StringConverter
# value.converter=org.apache.kafka.connect.json.JsonConverter
